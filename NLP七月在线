【7.词向量与相关应用】

1.常见任务
自动摘要（提取用于索引）、指代消解（明白指代对象）、机器翻译、词性标注、分词、主题识别、文本分类...

2.NLP处理方法
传统：基于规则
现代：基于统计学习
    - HMM, CRF, SVM, LDA, CNN...
    - “规则”隐含在模型参数中

3.向量空间子结构
最终目标：词向量表示作为机器学习，特别是深度学习的输入和表示空间
//数据决定结果上限。算法决定多大程度逼近上限。

4.离散表示
One-hot表示
    语料库->词典->One-hot表示（每个单词有唯一索引）
Bag of Words
    词权重（无序）
        TF-IDF:
            TF: 词频
            IDF: log(1+N/nt) //N文档总数，含有词t的文档数
            
5.Bi-gram和N-gram
为2-gram建立索引：“John likes”
    优点：考虑了词的顺序
    缺点：词表膨胀
    
6.离散表示的问题
无法衡量词向量之间关系
维度膨胀
数据稀疏

7.分布式表示
1*2*3
共现矩阵：Word-Word
    局域窗
    维度过高：SVD降维
    
8.NNLM（Neural Network Language Model）
使用了非对称的前向窗函数，窗长度n-1
...

9.word2vec:CBOW（连续词袋）
无隐层，使用双向上下文窗口，上下文词序无关（BOW），输入层低维稠密表示，投影层简化为求和（平均）
J = sigma P(w|context(w))
Softmax输出, 希望CPU快速建模
改进：层次Softmax，使用Huffman树编码->log2，若干个LR，权重共享
    路径->sigmoid

10.负例采样
负样本采样子集
