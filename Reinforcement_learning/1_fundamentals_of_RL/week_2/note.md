# Markov Decision Processes (MDP)

## Lesson 1: Introduction to Markov Decision Processes

Difference between bandits & MDP : 
- different situations call for different actions
- long-term impact

### Understand Markov Decision Processes, or MDPs

Environment -> (state, reward) -> Agent -> actions -> Envrironment

### Describe how the dynamics of an MDP are defined

### Understand the graphical representation of a Markov Decision Process

### Explain how many diverse processes can be written in terms of the MDP framework

## Lesson 2: Goal of Reinforcement Learning

To maximize the expected return.

### Describe how rewards relate to the goal of an agent

G_t = R_t+1 + R_t+2 + R_t+3 + ... + R_T

### Understand episodes and identify episodic tasks

Episodic tasks : the agent-environment interation breaks up into episodes.

Reward hypothesis :  programming -> supervised learning -> RL

## Lesson 3: Continuing Tasks

### Formulate returns for continuing tasks using discounting

### Describe how returns at successive time steps are related to each other

### Understand when to formalize a task as episodic or continuing
