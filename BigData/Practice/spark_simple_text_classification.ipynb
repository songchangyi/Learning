{"cells":[{"metadata":{},"cell_type":"markdown","source":"The objective of this notebook is to learn using PySpark ML with the help of other's public code in the context of comments classification.\n\nThe origin notebook proposed a basic solution for text processing :  https://www.kaggle.com/danielokeeffe/simple-text-classification-with-apache-spark/data"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pyspark","execution_count":3,"outputs":[{"output_type":"stream","text":"Collecting pyspark\n  Downloading pyspark-2.4.5.tar.gz (217.8 MB)\n\u001b[K     |████████████████████████████████| 217.8 MB 5.2 kB/s  eta 0:00:01\n\u001b[?25hCollecting py4j==0.10.7\n  Downloading py4j-0.10.7-py2.py3-none-any.whl (197 kB)\n\u001b[K     |████████████████████████████████| 197 kB 32.8 MB/s eta 0:00:01\n\u001b[?25hBuilding wheels for collected packages: pyspark\n  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pyspark: filename=pyspark-2.4.5-py2.py3-none-any.whl size=218258791 sha256=bb534cc1de7dee4ee80145803d4095c5069eca77d4822f2ecda6027f4ed5a821\n  Stored in directory: /root/.cache/pip/wheels/84/30/e3/c51c5cd0229631e662d29d7b578a3e5949a4c8db033ffb70aa\nSuccessfully built pyspark\nInstalling collected packages: py4j, pyspark\nSuccessfully installed py4j-0.10.7 pyspark-2.4.5\n","name":"stdout"}]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"### Import"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\n\n# analysis\nfrom pyspark.sql import SparkSession\nimport pyspark.sql.functions as F\nimport pyspark.sql.types as T\n\n# feature engineering\nfrom pyspark.ml.feature import Tokenizer, HashingTF, IDF\n\n# classification\nfrom pyspark.ml.classification import LogisticRegression","execution_count":4,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Build a spark context"},{"metadata":{"trusted":true},"cell_type":"code","source":"hc = (SparkSession.builder\n                  .appName('Toxic Comment Classification')\n                  .enableHiveSupport()\n                  .config(\"spark.executor.memory\", \"4G\")\n                  .config(\"spark.driver.memory\",\"18G\")\n                  .config(\"spark.executor.cores\",\"7\")\n                  .config(\"spark.python.worker.memory\",\"4G\")\n                  .config(\"spark.driver.maxResultSize\",\"0\")\n                  .config(\"spark.sql.crossJoin.enabled\", \"true\")\n                  .config(\"spark.serializer\",\"org.apache.spark.serializer.KryoSerializer\")\n                  .config(\"spark.default.parallelism\",\"2\")\n                  .getOrCreate())\n\n# log configuration\nhc.sparkContext.setLogLevel('INFO')\n\n# version\nhc.version","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"'2.4.5'"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Load data"},{"metadata":{},"cell_type":"markdown","source":"- Load data into Pandas.\n- Convert Pandas DF to Spark DF"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":10,"outputs":[{"output_type":"stream","text":"/kaggle/input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv.zip\n/kaggle/input/jigsaw-toxic-comment-classification-challenge/test_labels.csv.zip\n/kaggle/input/jigsaw-toxic-comment-classification-challenge/test.csv.zip\n/kaggle/input/jigsaw-toxic-comment-classification-challenge/train.csv.zip\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def to_spark_df(fin):\n    \"\"\"\n    Parse a filepath to a spark dataframe using the pandas api.\n    \n    Parameters\n    ----------\n    fin : str\n        The path to the file on the local filesystem that contains the csv data.\n        \n    Returns\n    -------\n    df : pyspark.sql.dataframe.DataFrame\n        A spark DataFrame containing the parsed csv data.\n    \"\"\"\n    df = pd.read_csv(fin)\n    df.fillna(\"\", inplace=True)\n    df = hc.createDataFrame(df)\n    return(df)\n\n# Load the train-test sets\ntrain = to_spark_df(\"../input/jigsaw-toxic-comment-classification-challenge/train.csv.zip\")\ntest = to_spark_df(\"../input/jigsaw-toxic-comment-classification-challenge/test.csv.zip\")","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.show(5)","execution_count":17,"outputs":[{"output_type":"stream","text":"+----------------+--------------------+-----+------------+-------+------+------+-------------+\n|              id|        comment_text|toxic|severe_toxic|obscene|threat|insult|identity_hate|\n+----------------+--------------------+-----+------------+-------+------+------+-------------+\n|0000997932d777bf|Explanation\nWhy t...|    0|           0|      0|     0|     0|            0|\n|000103f0d9cfb60f|D'aww! He matches...|    0|           0|      0|     0|     0|            0|\n|000113f07ec002fd|Hey man, I'm real...|    0|           0|      0|     0|     0|            0|\n|0001b41b1c6bb37e|\"\nMore\nI can't ma...|    0|           0|      0|     0|     0|            0|\n|0001d958c54c6e35|You, sir, are my ...|    0|           0|      0|     0|     0|            0|\n+----------------+--------------------+-----+------------+-------+------+------+-------------+\nonly showing top 5 rows\n\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Feature Engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"out_cols = [i for i in train.columns if i not in [\"id\", \"comment_text\"]]","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# View some toxic comments\ntrain.filter(F.col('toxic') == 1).show(5)","execution_count":19,"outputs":[{"output_type":"stream","text":"+----------------+--------------------+-----+------------+-------+------+------+-------------+\n|              id|        comment_text|toxic|severe_toxic|obscene|threat|insult|identity_hate|\n+----------------+--------------------+-----+------------+-------+------+------+-------------+\n|0002bcb3da6cb337|COCKSUCKER BEFORE...|    1|           1|      1|     0|     1|            0|\n|0005c987bdfc9d4b|Hey... what is it...|    1|           0|      0|     0|     0|            0|\n|0007e25b2121310b|Bye! \n\nDon't look...|    1|           0|      0|     0|     0|            0|\n|001810bf8c45bf5f|You are gay or an...|    1|           0|      1|     0|     1|            1|\n|00190820581d90ce|FUCK YOUR FILTHY ...|    1|           0|      1|     0|     1|            0|\n+----------------+--------------------+-----+------------+-------+------+------+-------------+\nonly showing top 5 rows\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Basic sentence tokenizer\ntokenizer = Tokenizer(inputCol=\"comment_text\", outputCol=\"words\")\nwordsData = tokenizer.transform(train)","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Count the words in a document\nhashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\")\ntf = hashingTF.transform(wordsData)","execution_count":23,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.select('rawFeatures').take(2)","execution_count":26,"outputs":[{"output_type":"execute_result","execution_count":26,"data":{"text/plain":"[Row(rawFeatures=SparseVector(262144, {19208: 1.0, 23032: 1.0, 24417: 1.0, 25000: 1.0, 29945: 1.0, 32241: 1.0, 32976: 1.0, 37852: 1.0, 46075: 1.0, 59853: 1.0, 72125: 1.0, 77971: 1.0, 81631: 1.0, 82999: 1.0, 83922: 1.0, 91677: 1.0, 97171: 1.0, 100258: 1.0, 101169: 1.0, 103838: 3.0, 110427: 1.0, 113031: 1.0, 113418: 1.0, 135568: 1.0, 139533: 1.0, 140784: 1.0, 145284: 1.0, 151536: 1.0, 164148: 1.0, 169364: 1.0, 176964: 1.0, 182267: 1.0, 192137: 1.0, 193131: 1.0, 229137: 1.0, 230921: 1.0, 231630: 1.0, 244466: 1.0, 246621: 1.0, 249835: 1.0, 253170: 1.0})),\n Row(rawFeatures=SparseVector(262144, {17429: 1.0, 38728: 1.0, 83815: 1.0, 88337: 1.0, 101527: 1.0, 101833: 1.0, 108541: 1.0, 125765: 1.0, 141219: 1.0, 151980: 1.0, 169364: 1.0, 169800: 1.0, 203235: 1.0, 208090: 1.0, 219140: 1.0, 242101: 1.0, 248135: 1.0, 249180: 1.0}))]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build the idf model and transform the original token frequencies into their tf-idf counterparts\nidf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\nidfModel = idf.fit(tf) \ntfidf = idfModel.transform(tf)","execution_count":27,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tfidf.select(\"features\").first()","execution_count":28,"outputs":[{"output_type":"execute_result","execution_count":28,"data":{"text/plain":"Row(features=SparseVector(262144, {19208: 2.244, 23032: 5.0123, 24417: 0.7386, 25000: 5.6813, 29945: 3.0517, 32241: 8.3967, 32976: 5.0285, 37852: 1.7539, 46075: 6.9564, 59853: 3.1525, 72125: 2.2744, 77971: 7.6108, 81631: 3.4198, 82999: 7.5735, 83922: 6.4588, 91677: 0.6965, 97171: 2.0163, 100258: 1.1947, 101169: 1.734, 103838: 1.2127, 110427: 2.1173, 113031: 8.9845, 113418: 2.2023, 135568: 3.5864, 139533: 2.5136, 140784: 3.0483, 145284: 7.6628, 151536: 2.2412, 164148: 6.0064, 169364: 2.4772, 176964: 1.7656, 182267: 8.613, 192137: 3.1018, 193131: 5.6703, 229137: 4.5705, 230921: 2.0429, 231630: 8.2914, 244466: 3.351, 246621: 10.0343, 249835: 6.827, 253170: 2.7021}))"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"tfidf.show(5)","execution_count":30,"outputs":[{"output_type":"stream","text":"+----------------+--------------------+-----+------------+-------+------+------+-------------+--------------------+--------------------+--------------------+\n|              id|        comment_text|toxic|severe_toxic|obscene|threat|insult|identity_hate|               words|         rawFeatures|            features|\n+----------------+--------------------+-----+------------+-------+------+------+-------------+--------------------+--------------------+--------------------+\n|0000997932d777bf|Explanation\nWhy t...|    0|           0|      0|     0|     0|            0|[explanation, why...|(262144,[19208,23...|(262144,[19208,23...|\n|000103f0d9cfb60f|D'aww! He matches...|    0|           0|      0|     0|     0|            0|[d'aww!, he, matc...|(262144,[17429,38...|(262144,[17429,38...|\n|000113f07ec002fd|Hey man, I'm real...|    0|           0|      0|     0|     0|            0|[hey, man,, i'm, ...|(262144,[14,9639,...|(262144,[14,9639,...|\n|0001b41b1c6bb37e|\"\nMore\nI can't ma...|    0|           0|      0|     0|     0|            0|[\", more, i, can'...|(262144,[4081,517...|(262144,[4081,517...|\n|0001d958c54c6e35|You, sir, are my ...|    0|           0|      0|     0|     0|            0|[you,, sir,, are,...|(262144,[37852,39...|(262144,[37852,39...|\n+----------------+--------------------+-----+------------+-------+------+------+-------------+--------------------+--------------------+--------------------+\nonly showing top 5 rows\n\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Modeling"},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = LogisticRegression(featuresCol=\"features\", labelCol='toxic', regParam=0.1)","execution_count":29,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lrModel = lr.fit(tfidf.limit(5000))","execution_count":31,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res_train = lrModel.transform(tfidf)","execution_count":34,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res_train.select(\"id\", \"toxic\", \"probability\", \"prediction\").show(20)","execution_count":37,"outputs":[{"output_type":"stream","text":"+----------------+-----+--------------------+----------+\n|              id|toxic|         probability|prediction|\n+----------------+-----+--------------------+----------+\n|0000997932d777bf|    0|[0.98581646633835...|       0.0|\n|000103f0d9cfb60f|    0|[0.98344821303795...|       0.0|\n|000113f07ec002fd|    0|[0.95500173136246...|       0.0|\n|0001b41b1c6bb37e|    0|[0.99453009308165...|       0.0|\n|0001d958c54c6e35|    0|[0.96269618805532...|       0.0|\n|00025465d4725e87|    0|[0.95766822132553...|       0.0|\n|0002bcb3da6cb337|    1|[0.27147906115805...|       1.0|\n|00031b1e95af7921|    0|[0.96287942446786...|       0.0|\n|00037261f536c51d|    0|[0.98502026615636...|       0.0|\n|00040093b2687caa|    0|[0.96974700476352...|       0.0|\n|0005300084f90edc|    0|[0.99999214813733...|       0.0|\n|00054a5e18b50dd4|    0|[0.96909930941050...|       0.0|\n|0005c987bdfc9d4b|    1|[0.04657011154294...|       1.0|\n|0006f16e4e9f292e|    0|[0.99600536691196...|       0.0|\n|00070ef96486d6f9|    0|[0.98042892897313...|       0.0|\n|00078f8ce7eb276d|    0|[0.99157617779791...|       0.0|\n|0007e25b2121310b|    1|[0.20164110039400...|       1.0|\n|000897889268bc93|    0|[0.97616369741436...|       0.0|\n|0009801bd85e5806|    0|[0.98010032569437...|       0.0|\n|0009eaea3325de8c|    0|[0.98840835604315...|       0.0|\n+----------------+-----+--------------------+----------+\nonly showing top 20 rows\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"extract_prob = F.udf(lambda x: float(x[1]), T.FloatType())","execution_count":42,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res_train.withColumn(\"proba\", extract_prob(\"probability\")).select(\"proba\", \"prediction\").show()","execution_count":43,"outputs":[{"output_type":"stream","text":"+-----------+----------+\n|      proba|prediction|\n+-----------+----------+\n|0.014183533|       0.0|\n|0.016551787|       0.0|\n| 0.04499827|       0.0|\n|0.005469907|       0.0|\n|0.037303813|       0.0|\n|0.042331778|       0.0|\n| 0.72852093|       1.0|\n|0.037120577|       0.0|\n|0.014979734|       0.0|\n|0.030252995|       0.0|\n|7.851862E-6|       0.0|\n| 0.03090069|       0.0|\n|  0.9534299|       1.0|\n|0.003994633|       0.0|\n|0.019571071|       0.0|\n|0.008423822|       0.0|\n|  0.7983589|       1.0|\n|0.023836304|       0.0|\n|0.019899674|       0.0|\n|0.011591644|       0.0|\n+-----------+----------+\nonly showing top 20 rows\n\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_tokens = tokenizer.transform(test)\ntest_tf = hashingTF.transform(test_tokens)\ntest_tfidf = idfModel.transform(test_tf)","execution_count":44,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_res = test.select('id')\ntest_res.head()","execution_count":50,"outputs":[{"output_type":"execute_result","execution_count":50,"data":{"text/plain":"Row(id='00001cee341fdb12')"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_probs = []\nfor col in out_cols:\n    print(col)\n    lr = LogisticRegression(featuresCol=\"features\", labelCol=col, regParam=0.1)\n    print(\"...fitting\")\n    lrModel = lr.fit(tfidf)\n    print(\"...predicting\")\n    res = lrModel.transform(test_tfidf)\n    print(\"...appending result\")\n    test_res = test_res.join(res.select('id', 'probability'), on=\"id\")\n    print(\"...extracting probability\")\n    test_res = test_res.withColumn(col, extract_prob('probability')).drop(\"probability\")\n    test_res.show(5)","execution_count":null,"outputs":[{"output_type":"stream","text":"toxic\n...fitting\n...predicting\n...appending result\n...extracting probability\n+----------------+------------+\n|              id|       toxic|\n+----------------+------------+\n|000968ce11f5ee34|  0.04655437|\n|00491682330fdd1d|3.6486778E-8|\n|008eb47c4684d190|   0.6308229|\n|00d251f47486b6d2|  0.06102414|\n|0114ae82c53101a9|  0.43038085|\n+----------------+------------+\nonly showing top 5 rows\n\nsevere_toxic\n...fitting\n...predicting\n...appending result\n...extracting probability\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_res.coalesce(1).write.csv('./results/spark_lr.csv', mode='overwrite', header=True)\n!cat results/spark_lr.csv/part*.csv > spark_lr.csv","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}